# Activities

* Added about 6000 images to dataset for training/validation
  * Did this using MazeGen.py and autogen_edited_Marchese
* Created Notebook to take left-right and right-left images out of dataset
* Trained torch and fastai models on larger dataset, tested and compared performance of models in mazes they were trained on and a maze they weren't trained on
  * Ultimately, models trained on larger dataset that had added dropout and batch normalization did the best on the mazes across the board
  * Found that adding if-conditional that prevents left-right movement sequence actually makes the best models do significantly worse 
  (but with models that didn't do well in a given maze, the if-conditional tended to improve performance)
  * Torch model with dropout and batch normalization did slightly better than the fastai model with dropout and batch normalization
* Tested out different resnets on the models with added batch normalization and dropout
  * Trained and validated these models on ~7000 images
  * By the assessment metric of steps, the models with the pretrained architecture of the resnet18 did the best compared to models using resnet34s, resnet50s, and resnet101s
  * Of all 6 models, the resnet101s did the worst with both the fastai and torch versions unable to complete the test maze
  * All other resnet models (torch and fastai) were able to complete the maze (with the exception of the torch model that used the resnet50 architecture)
* Tested xresnets (18, 34, 50, 101) (read article about how these would probably underperform because pretrained weights aren't available for them)
  * No xresnets made it through the maze
* Went through debugging and fastai source code with Professor Clark in attempt to find a solution to our issue with cnn_learner not taking custom models
  * Attempted to create custom_head for cnn_learner and cmd model application
* Side project:
  * Fixed old code and poster for PEARC conference

# Issues

* When attempting to create a custom_head, came across the issue of being able to make the head but not able to ensure the previous command is taken into account properly when the model is learning as I could do in the "forward" function of my other model classes
  * This issue especially became prevalent when I ran the code to fine tune the model and was given the error: "conv2d(): argument 'input' (position 1) must be Tensor, not tuple."
  * Thinking I will either need to change the dataset for this or maybe I could run the two networks separately on cnn_learner then concatenate them and train that throught fastai's learner
  * Am I able to make a custom forward function via fastai? If I can control the flow of the data then maybe this issue can be resolved...

# Plans

* Continue testing different architectures
* Continue attempting to get around cnn_learner problem
* Learn CAD to start working on creating robot parts
