# Activities

* Edited the output of the pytorch model when training to include times and when going through the validation set to include class accuracy
* Put everything on the GPU to increase training speed
* Fixed pytorch model validation set (using argmax instead of torch.max)
* Tested different learning rates
* Added initial weights to pytorch model
* Fixed issue with splitting the dataset in pytorch model
* Made models with different hidden layers (dropout layers/batch normalization) and tested how the layers affected performance in the maze
  * cmd_torch -> pytorch model with no added dropout layers or batch normalization
	  * Trained on 15 epochs to get 0.0 training loss (rounded to one decimal place); lr=0.0001
	  * 94.27% accuracy on validation set
	  * Overturned at one point then fixed itself
	  * It got to the end! Completed the maze! 1295 steps
	 * cmd_torch1 -> pytorch model with added dropout layers but no batch normalization; lr=0.0001
	  * trained on 20 epochs to get 0.1 training loss (rounded to one decimal place)
	  * 93.83% accuracy on validation set 
	  * hit corner, tried to fix itself, and got stuck at around 900 steps
	  * Ended at position 9.522856063951625, 15.002036559366598
  * cmd_torch2 -> pytorch model with added dropout layers and batch normalization
   *  
* Read OpenBot paper
* Began reading paper on dropout layers

# Issues

* Server issues this week
* Still having issues with cnn_learner for fastai model

# Plans

* Need to train models on more image data
  * Generate more mazes, use edited autogen to generate more image data with proper labels
* Try out different resnets
* Try out different initial weights
* Try to get fastai model working better
* Interested in maybe trying some data augmentation, differing lighting, etc.
* Continue working through fastai course

# Article Summaries

[OpenBot: Turning Smartphones Into Robots](https://arxiv.org/pdf/2008.10631.pdf)

Researchers Muller and Koltun addressed the problem of accessibility in robot development, seeking to reduce the cost of development without sacrificing computational ability and comprehensive sensor architecture. Their approach to this problem involved using Android smartphones with extensive sensor suites, computational capabilities, and already established software ecosystems to reduce the cost of purchasing sensors, GPUs/CPUs, batteries, and displays separately. Ultimately, they were able to develop a wheeled robot with navigation and person-following capabilities for $50 plus the cost of a used Android smartphone. Their robot's software stack consisted of an Arduino for measuring wheel speed, batter voltage, etc. and an Android application which collected datasets (of images, GPS coordinates, and other sensor readings), provided an interface for remote control via a PS4/Xbox controller, and ran neural network models, using the Tensorflow Lite infrastructure, on the phones' mobile GPUs while also obtaining the output data.  In obtaining a dataset for training the robot's model, they used the game controller, getting image data and control labeling for a driving dataset as well as recovery manuevers. When the model was trained on data from different phones with different camera resolutions, model robustness increased (natural data augmentation). The network consists of five convolutional layers -- relu activation, batch normalization, and dropout were also used after each convolutional layer -- then the output went into two fully connected layers which was concatenated with a command multilayer perceptron and fed into another multilayer perceptron network. After all the fully-connected layers, a 50% dropout was applied. A weighted loss was used to account for imbalanced dataset ("a weighted term proportional to the steering angle combined with a standard MSE loss).

Applied to our problem, I am interested in looking into how data augmentation may improve model robustness, how recovery manuevers may help expand the dataset and teach the model how to fix its orientation, and how different amounts and combinations of dropout may help training.
