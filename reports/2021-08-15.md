# Activities

* Continued training models
  * Completed notpretrained uniform-full models
  * Started training corrected-wanderful pretrained models
  * Started training handmade-full pretrained models
* Finished training scripts for previous cmd models and RNN models
  * RNN models completed running
* Helped Oliver fix imitator for trained RNN models
* Continued reading papers and writing summaries

# Issues

* Can't use FastAI functions for confusion matrix, show result, show batch, because custom dataset
* Found out images in wandering dataset were the wrong size, needed to rerun all wandering models with corrected data

# Plans
* Continue training models
* Continue writing/outlining/editing paper

# Article Summaries

## Deep Neural Network for Real-Time Autonomous Indoor Navigation

Note: This paper similarly uses a classification convolutional neural networks for navigation. But these networks are directly applied to real world tasks.
I think what is especially interesting in this paper is their analysis of visualized feature maps they created, which allow them to see what characteristics were 
the most important in their network's training/learning.

Summary: The goal of this paper was to address how a Micro Aerial Vehicle (MAV) can navigate indoors and detect specific objects despite the limitations of GPS precision
in indoor spaces and despite the MAV not being able to carry heavy weight or power consuming sensors. The researchers proposed a convolutional neural network as a solution, 
training the network to take images from a single camera and categorize that image into 1 of 6 move classes (Forward, Right, Left, Spin Right, Spin Left, and Stop). Their 
network consisted of 5 convolutional layers and 3 fully connected layers. If the prediction confidence is low, the drone is set to just hover until the model outputs a move 
with more confidence. On a dataset collected from a variety of indoor spaces, the model was trained over 20,000 iterations with a batch size of 255. The model achieved 
between 70-80% accuracy; a trial was only considered successful if the MAV takes off and finds the correct target (a bookbag) without colliding into any obstacles. For 
visualizing aspects of the deep learning models, the researchers used class model visualization (creating a synthetic image that represents what a trained model is looking 
for in a specific class) and an image-specific class saliency map (indicating which part of an image affected a class score the most). 

## Convolutional Neural Networks for Food Image Recognition: An Experimental Study

Note: This study compares the MobileNetV2, ResNet50, InceptionV3, InceptionResNetV2, Xception, and Nasnet-Large architectures for the purpose of food image recognition. I
thought the comparison aspect aligned with our own as these models were tested on 3 different datasets as well.

Summary: The goal of this paper was to find the ideal CNN architecture, training dataset size, and image augmentation methods for the purpose of training an effective
food image recognition model. The models were trained and evaluated on 3 different datasets: UEC100 (Japanese cuisine), Food101 (Western cuisine), Food172 (Chinese cuisine)
-- all with between 100 and 172 classes -- for a max 80 epochs with a batch size of 8 (due to memory restraints). The researchers found that certain models tend to 
generalize better with fewer samples like the Xception network, which the researchers concluded as having the best balance between performance and efficiency. The researchers
also concluded that image augmentation techniques that do not alter shapes such as zoom, flip, and width height shift are more beneficial than other augmentation techniques 
and class imbalance is not really important as long as the class imbalance ratio is below 7. 

## Performance Comparison of Deep Neural Networks on Image Datasets

Note: This paper also compares different network architectures for image classification problems, specifically the VGG16, mobileNet, Resnet50, and InceptionV3. It gives
really good descriptions of each model architecture as well.

Summary: The goal of this paper was to evaluate different CNN architectures of two image datasets and assess their differing performances. They trained and validated the
models on a binary classification tasks (cats/dogs) (25,000 images) and a classification task of determining 1 of 12 seedling classes (2400 images). They were all trained 
for 10 epochs. The researchers concluded that the VGG16 is an accurate model but it takes too much time and computational resources. MobilNet was found to demonstrate superior
performance with respect to the resource vs. accuracy tradeoff. The Resnet model was said to be good if you want a deep model and/or you want to combine it with other networks
as it addresses the vanishing gradient problem well. Then lastly, the Inception model, using different kernel sizes at the same level allowed it to be good for a variety
of problems and have increased efficiency; although, it is also computationally expensive.
